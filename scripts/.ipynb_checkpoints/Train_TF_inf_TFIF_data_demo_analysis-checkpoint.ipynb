{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import math\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import subprocess as sp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "np.random.seed(4)\n",
    "\n",
    "from models import EarlyStopping, GRU\n",
    "from utilities import get_NSE, MSE, get_colors, print_notes, inverse_transform_sp\n",
    "from preprocess import load_data, SampleData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['deeppink', 'darkviolet', 'darkgray', 'darkblue', 'darkkhaki',\n",
       "       'deepskyblue', 'darkslategray', 'darkgreen', 'darkslategrey',\n",
       "       'darkseagreen', 'darkred', 'darkmagenta', 'darksalmon',\n",
       "       'darkorchid', 'darkorange', 'darkgoldenrod', 'darkturquoise',\n",
       "       'darkolivegreen', 'darkcyan', 'darkgrey', 'darkslateblue'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_gpu_memory():\n",
    "    _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "    ACCEPTABLE_AVAILABLE_MEMORY = 1024\n",
    "    COMMAND = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = _output_to_list(sp.check_output(COMMAND.split()))[1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "if get_gpu_memory()[0] < 1500 :\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Get colors\n",
    "colors = get_colors()\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_vars = ['SW_ENDmm']\n",
    "# run_task = 'Train_TF_inf_TFIF_SW'\n",
    "output_vars = ['SNOmm']\n",
    "run_task = 'Train_TF_inf_TFIF_SNO'\n",
    "# output_vars = ['Q_pred_mm']\n",
    "# run_task = 'Train_TF_inf_TFIF_SF'\n",
    "\n",
    "sim_type = 'full_wsl'\n",
    "rversion = 'hs32'\n",
    "#----------------paths-------------------\n",
    "res_dir = '../results/head_water_SWAT_1000_years/'\n",
    "exp_dir = res_dir + '{}/rversion_{}/'.format(run_task, rversion)\n",
    "\n",
    "#--------------------------------------------- load input data -----------------------------\n",
    "new_data_dir = '../data/1000_year_simulation/'\n",
    "if sim_type =='full_wsl':\n",
    "    path = new_data_dir + 'head_water_SWAT_1000_years.csv'\n",
    "elif sim_type =='nosnow_nofrozen_wsl':\n",
    "    path = new_data_dir + 'head_water_SWAT_1000_years_no_snow_no_frozen.csv'\n",
    "elif sim_type =='nosnow_wsl':\n",
    "    path = new_data_dir + 'head_water_SWAT_1000_years_no_snow.csv'\n",
    "else:\n",
    "    raise FileNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network hypermeters : \n",
      "learning_rate 0.01\n",
      "epochs 500\n",
      "batch_size 64\n",
      "hidden_size 32\n",
      "input_size 8\n",
      "n_steps 366\n",
      "dropout 0.0\n",
      "n_classes 1\n",
      "num_samples_train 0\n",
      "shift_train 183\n",
      "num_samples_valid 0\n",
      "shift_valid 183\n",
      "num_samples_test 0\n",
      "shift_test 183\n",
      "train_percentage 0.5\n",
      "valid_percentage 0.1\n",
      "\n",
      "Goal: Simulate the target variable using 7 weather drivers including Date, PRECIPmm, TMP_MXdgC, TMP_MNdgC, SOLARMJ/m2, WINDM/s, RHmd\n",
      "Target variables: SW_ENDmm, SNOmm, Q_pred_mm\n",
      "Data: 1000 years simulation data\n",
      "Split data: First 50% of data as the training set, middle 10% of data as the validation set,  last 40% of data as the testing set\n",
      "Settings:\n",
      "- Training: Random mini-batch (RMB) algorithm\n",
      "- Model: one layer GRU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_iter = 5\n",
    "max_iter = run_iter\n",
    "n_steps = 366\n",
    "hidden_size = 32\n",
    "epochs = 500\n",
    "learning_rate = 0.01\n",
    "n_classes = len(output_vars)\n",
    "batch_size = 64\n",
    "input_size = 7\n",
    "dropout = 0\n",
    "nlayers=1\n",
    "patience = 50\n",
    "\n",
    "input_vars = ['Date', 'PRECIPmm', 'TMP_MXdgC', 'TMP_MNdgC', 'SOLARMJ/m2', 'WINDM/s', 'RHmd']\n",
    "assert(len(input_vars) == input_size)\n",
    "\n",
    "params = np.load(exp_dir + 'params_ss_{}.npy'.format(n_steps),allow_pickle=True).tolist()\n",
    "print(\"The network hypermeters : \")\n",
    "for k,v in params.items():\n",
    "    if k != \"notes\":\n",
    "        print(k,v)\n",
    "    if k == \"notes\":\n",
    "        print()\n",
    "        print_notes(params['notes'][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)\n",
    "feat, label = load_data(df, output_vars, input_vars, input_size)\n",
    "label_shift = np.expand_dims([label[0,0]] + list(np.squeeze(label[:-1])), axis=1)\n",
    "feat = np.concatenate((feat, label_shift), axis=-1)\n",
    "input_size = input_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182622 36524 146098\n",
      "182622\n",
      "36524\n",
      "146098\n"
     ]
    }
   ],
   "source": [
    "# First 50% of data as the training set, middle 10% of data as the validation set, last 40% of data as the testing set.\n",
    "train_percentage = 0.5\n",
    "valid_percentage = 0.1\n",
    "test_percentage = 1 - (train_percentage + valid_percentage)\n",
    "\n",
    "# Split data\n",
    "T = feat.shape[0]\n",
    "train_len = int(T*train_percentage)\n",
    "valid_len = int(T*valid_percentage)\n",
    "test_len = T - train_len - valid_len\n",
    "print(train_len,valid_len,test_len)\n",
    "train_x = feat[:train_len].copy()\n",
    "train_y = label[:train_len].copy()\n",
    "valid_x = feat[train_len:train_len+valid_len].copy()\n",
    "valid_y = label[train_len:train_len+valid_len].copy()\n",
    "test_x = feat[train_len+valid_len:].copy()\n",
    "test_y = label[train_len+valid_len:].copy()\n",
    "\n",
    "# Normalize data\n",
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(train_x) \n",
    "x_train = scaler_x.transform(train_x)\n",
    "x_valid = scaler_x.transform(valid_x)\n",
    "x_test = scaler_x.transform(test_x)\n",
    "scaler_y = StandardScaler()\n",
    "scaler_y.fit(train_y)\n",
    "y_train = scaler_y.transform(train_y)\n",
    "y_valid = scaler_y.transform(valid_y)\n",
    "y_test = scaler_y.transform(test_y)\n",
    "m_test = y_test.copy()\n",
    "m_test[:,:] = 1\n",
    "\n",
    "# Sample data\n",
    "## Get indexes\n",
    "train_idx = np.arange(len(y_train))\n",
    "valid_idx = np.arange(len(y_valid))\n",
    "test_idx = np.arange(len(y_test))\n",
    "## Set stride\n",
    "num_samples_train = 0\n",
    "shift_train = int(n_steps / 2)\n",
    "num_samples_valid = 0\n",
    "shift_valid = int(n_steps / 2)\n",
    "num_samples_test = 0\n",
    "shift_test = int(n_steps / 2)\n",
    "## Get lists of indexes to sample data. \n",
    "train_idx_arr = SampleData(train_idx,n_steps,shift_train,num_samples_train)\n",
    "num_train_samples = train_idx_arr.shape[0]\n",
    "valid_idx_arr = SampleData(valid_idx,n_steps,shift_valid,num_samples_valid)\n",
    "num_valid_samples = valid_idx_arr.shape[0]\n",
    "test_idx_arr = SampleData(test_idx,n_steps,shift_test,num_samples_test)\n",
    "num_test_samples = test_idx_arr.shape[0]\n",
    "## Sample data\n",
    "x_train_sp_ = x_train[train_idx_arr,:]\n",
    "y_train_sp_ = y_train[train_idx_arr,:]\n",
    "m_train_sp_ = y_train_sp_.copy()\n",
    "m_train_sp_[:,:,:] = 1 # no masking\n",
    "x_valid_sp_ = x_valid[valid_idx_arr,:]\n",
    "y_valid_sp_ = y_valid[valid_idx_arr,:]\n",
    "m_valid_sp_ = y_valid_sp_.copy()\n",
    "m_valid_sp_[:,:,:] = 1 # no masking\n",
    "x_test_sp_ = x_test[test_idx_arr,:]\n",
    "y_test_sp_ = y_test[test_idx_arr,:]\n",
    "m_test_sp_ = y_test_sp_.copy()\n",
    "m_test_sp_[:,:,:] = 1 # no masking\n",
    "\n",
    "# Send data to the device\n",
    "x_train_sp = torch.from_numpy(x_train_sp_).type(torch.float32).to(device)\n",
    "y_train_sp = torch.from_numpy(y_train_sp_).type(torch.float32).to(device)\n",
    "m_train_sp = torch.from_numpy(m_train_sp_).type(torch.float32).to(device)\n",
    "\n",
    "x_valid_sp = torch.from_numpy(x_valid_sp_).type(torch.float32).to(device)\n",
    "y_valid_sp = torch.from_numpy(y_valid_sp_).type(torch.float32).to(device)\n",
    "m_valid_sp = torch.from_numpy(m_valid_sp_).type(torch.float32).to(device)\n",
    "\n",
    "x_test_sp = torch.from_numpy(x_test_sp_).type(torch.float32).to(device)\n",
    "y_test_sp = torch.from_numpy(y_test_sp_).type(torch.float32).to(device)\n",
    "m_test_sp = torch.from_numpy(m_test_sp_).type(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.from_numpy(x_test).type(torch.float32).to(device)\n",
    "y_test = torch.from_numpy(y_test).type(torch.float32).to(device)\n",
    "m_test = torch.from_numpy(m_test).type(torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([146098, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Total epoch : 454\n",
      "Total training time : 21.8447\n",
      "Iteration 1\n",
      "Total epoch : 485\n",
      "Total training time : 20.9617\n",
      "Iteration 2\n",
      "Total epoch : 428\n",
      "Total training time : 22.5404\n",
      "Iteration 3\n",
      "Total epoch : 432\n",
      "Total training time : 20.8416\n",
      "Iteration 4\n",
      "Total epoch : 406\n",
      "Total training time : 19.7053\n",
      "0.0480 second/epoch\n"
     ]
    }
   ],
   "source": [
    "# Analyze the training time\n",
    "tot_epoch = 0\n",
    "tot_time = 0\n",
    "for run_iter in np.arange(max_iter):\n",
    "    print('Iteration {}'.format(run_iter))\n",
    "    # # Load the final epoch model\n",
    "    path_save = exp_dir+\"run_iter_{}_final_model.sav\".format(run_iter)\n",
    "    checkpoint=torch.load(path_save)\n",
    "    epoch = checkpoint['epoch']\n",
    "    training_time = checkpoint['train_time']\n",
    "    tot_epoch += epoch\n",
    "    tot_time += training_time\n",
    "    print(\"Total epoch : {}\".format(epoch))\n",
    "    print(\"Total training time : {:.4f}\".format(training_time))\n",
    "    \n",
    "print(\"{:.4f} second/epoch\".format(tot_time / tot_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-TF Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE Mean\n",
      "[2.56  2.839 2.716 2.763 2.881]\n",
      "Test RMSE Mean : 2.752\n",
      "Test RMSE STDV : 0.112\n",
      "Test NSE\n",
      "[0.953 0.942 0.947 0.945 0.94 ]\n",
      "Test NSE Mean : 0.945\n",
      "Test NSE STDV : 0.004\n",
      "Test RMSE Mean\n",
      "[2.067 1.947 2.077 1.989 2.107]\n",
      "Test RMSE Mean : 2.037\n",
      "Test RMSE STDV : 0.060\n",
      "Test NSE\n",
      "[0.969 0.973 0.969 0.972 0.968]\n",
      "Test NSE Mean : 0.970\n",
      "Test NSE STDV : 0.002\n",
      "Test RMSE Mean\n",
      "[1.388 1.119 1.275 1.212 1.191]\n",
      "Test RMSE Mean : 1.237\n",
      "Test RMSE STDV : 0.091\n",
      "Test NSE\n",
      "[0.986 0.991 0.988 0.989 0.99 ]\n",
      "Test NSE Mean : 0.989\n",
      "Test NSE STDV : 0.002\n",
      "Test RMSE Mean\n",
      "[0.921 0.92  0.896 0.948 0.911]\n",
      "Test RMSE Mean : 0.919\n",
      "Test RMSE STDV : 0.017\n",
      "Test NSE\n",
      "[0.994 0.994 0.994 0.994 0.994]\n",
      "Test NSE Mean : 0.994\n",
      "Test NSE STDV : 0.000\n",
      "Test RMSE Mean\n",
      "[0.587 0.569 0.624 0.595 0.588]\n",
      "Test RMSE Mean : 0.593\n",
      "Test RMSE STDV : 0.018\n",
      "Test NSE\n",
      "[0.998 0.998 0.997 0.997 0.998]\n",
      "Test NSE Mean : 0.997\n",
      "Test NSE STDV : 0.000\n",
      "Test RMSE Mean\n",
      "[0.452 0.455 0.465 0.446 0.466]\n",
      "Test RMSE Mean : 0.457\n",
      "Test RMSE STDV : 0.007\n",
      "Test NSE\n",
      "[0.999 0.999 0.998 0.999 0.998]\n",
      "Test NSE Mean : 0.998\n",
      "Test NSE STDV : 0.000\n",
      "Test RMSE Mean\n",
      "[0.32  0.373 0.33  0.311 0.334]\n",
      "Test RMSE Mean : 0.334\n",
      "Test RMSE STDV : 0.021\n",
      "Test NSE\n",
      "[0.999 0.999 0.999 0.999 0.999]\n",
      "Test NSE Mean : 0.999\n",
      "Test NSE STDV : 0.000\n"
     ]
    }
   ],
   "source": [
    "pred_test_itrs_data = []\n",
    "hiddens_test_itrs_data = []\n",
    "mean_rmse_data = []\n",
    "stdv_rmse_data = []\n",
    "mean_nse_data = []\n",
    "stdv_nse_data = []\n",
    "\n",
    "for train_years in [5, 10, 20, 40, 80, 160, 500]:\n",
    "    exp_dir = res_dir + '{}/rversion_{}_years_{}/'.format(run_task, rversion, train_years)\n",
    "    if train_years == 500:\n",
    "        exp_dir = res_dir + '{}/rversion_{}/'.format(run_task, rversion)\n",
    "\n",
    "\n",
    "    x_test_copy = x_test.clone().detach()\n",
    "    pred_test_itrs = []\n",
    "    hiddens_test_itrs = []\n",
    "    rmses_test_itrs = []\n",
    "    for run_iter in np.arange(max_iter):\n",
    "        # print('Iteration {}'.format(run_iter))\n",
    "        # Load the best validation model\n",
    "        path_save = exp_dir+\"run_iter_{}_best_model.sav\".format(run_iter)\n",
    "        checkpoint=torch.load(path_save)\n",
    "        model_trained=GRU(input_size, hidden_size, nlayers, n_classes, dropout)\n",
    "        model_trained.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model_trained.to(device)\n",
    "        epoch = checkpoint['epoch']\n",
    "        # print(\"Best epoch is {}\".format(epoch))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_trained.eval()\n",
    "            hidden_head = model_trained.init_hidden(1)\n",
    "            X = x_test[None, :,:].to(device)\n",
    "            pred_test,hiddens_test = model_trained(X,hidden_head)\n",
    "            pred_test = pred_test.cpu().numpy().reshape(-1,1)\n",
    "            hiddens_test = np.squeeze(hiddens_test.cpu().numpy())\n",
    "            pred_test = scaler_y.inverse_transform(pred_test)\n",
    "            loss_test = MSE(pred_test, test_y)\n",
    "            rmses_test_itrs.append(np.sqrt(loss_test))\n",
    "            # print(\"Epoch {} : epoch_loss_test RMSE loss {:.4f}\".format(str(epoch), np.sqrt(loss_test)))\n",
    "            # print()\n",
    "        pred_test_itrs.append(pred_test)\n",
    "        hiddens_test_itrs.append(hiddens_test)\n",
    "    pred_test_itrs = np.squeeze(pred_test_itrs)\n",
    "    hiddens_test_itrs = np.squeeze(hiddens_test_itrs)\n",
    "    \n",
    "    pred_test_itrs_data.append(pred_test_itrs)\n",
    "    hiddens_test_itrs_data.append(hiddens_test_itrs)\n",
    "    \n",
    "    y_sp = np.squeeze(y_test_sp.cpu().numpy())\n",
    "    m_sp = np.squeeze(m_test_sp.cpu().numpy())\n",
    "    y_ori =  y_sp.reshape(-1,n_classes)\n",
    "    y_ori = scaler_y.inverse_transform(y_ori).reshape(y_sp.shape)\n",
    "    idx_arr = test_idx_arr\n",
    "    \n",
    "    with open(exp_dir + \"pred_test_itrs.npy\", 'wb') as f:\n",
    "        np.save(f, pred_test_itrs)\n",
    "    with open(exp_dir + \"test_idx_arr.npy\", 'wb') as f:\n",
    "        np.save(f, test_idx_arr)\n",
    "    \n",
    "    rmse_test_itrs = []\n",
    "    nse_test_itrs=[]\n",
    "\n",
    "    for pred_test in pred_test_itrs:\n",
    "        rmse_test_itrs.append(np.sqrt(MSE(pred_test, np.squeeze(test_y))))\n",
    "        nse_test_itrs.append(get_NSE(np.squeeze(test_y), pred_test))\n",
    "        \n",
    "    print(\"Test RMSE Mean\")\n",
    "    print(np.round(rmse_test_itrs,3))\n",
    "    print(\"Test RMSE Mean : {:.3f}\".format(np.mean(rmse_test_itrs)))\n",
    "    print(\"Test RMSE STDV : {:.3f}\".format(np.std(rmse_test_itrs)))\n",
    "    \n",
    "    print(\"Test NSE\")\n",
    "    print(np.round(nse_test_itrs,3))\n",
    "    print(\"Test NSE Mean : {:.3f}\".format(np.mean(nse_test_itrs)))\n",
    "    print(\"Test NSE STDV : {:.3f}\".format(np.std(nse_test_itrs)))\n",
    "    \n",
    "    mean_rmse_data.append([train_years,np.mean(rmse_test_itrs)])\n",
    "    stdv_rmse_data.append([train_years,np.std(rmse_test_itrs)])\n",
    "    mean_nse_data.append([train_years,np.mean(nse_test_itrs)])\n",
    "    stdv_nse_data.append([train_years,np.std(nse_test_itrs)])\n",
    "    \n",
    "exp_dir = res_dir + '{}/rversion_{}/'.format(run_task, rversion)\n",
    "\n",
    "results_data = {'pred_test_itrs_data':np.squeeze(pred_test_itrs_data),\n",
    "               'mean_rmse_data':np.squeeze(mean_rmse_data), 'stdv_rmse_data':stdv_rmse_data,\n",
    "               'mean_nse_data':np.squeeze(mean_nse_data), 'stdv_nse_data':stdv_nse_data}\n",
    "with open(exp_dir+'results_data.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mean_rmse_data = np.squeeze(mean_rmse_data)\n",
    "# stdv_rmse_data = np.squeeze(stdv_rmse_data)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.errorbar(mean_rmse_data[:,0], mean_rmse_data[:,1], yerr=stdv_rmse_data[:,1], label='GRU')\n",
    "# # plt.title('RMSE of models')\n",
    "# plt.xlabel('training data size (years)')\n",
    "# plt.ylabel('RMSE')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-TFIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "40000\n",
      "80000\n",
      "120000\n",
      "0\n",
      "40000\n",
      "80000\n",
      "120000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "pred_test_itrs_data = []\n",
    "hiddens_test_itrs_data = []\n",
    "mean_rmse_data = []\n",
    "stdv_rmse_data = []\n",
    "mean_nse_data = []\n",
    "stdv_nse_data = []\n",
    "\n",
    "for train_years in [5, 10, 20, 40, 80, 160, 500]:\n",
    "    exp_dir = res_dir + '{}/rversion_{}_years_{}/'.format(run_task, rversion, train_years)\n",
    "    if train_years == 500:\n",
    "        exp_dir = res_dir + '{}/rversion_{}/'.format(run_task, rversion)\n",
    "\n",
    "    pred_test_itrs = []\n",
    "    for run_iter in np.arange(max_iter):\n",
    "        # print('Iteration {}'.format(run_iter))\n",
    "        # Load the best validation model\n",
    "        path_save = exp_dir+\"run_iter_{}_best_model.sav\".format(run_iter)\n",
    "        checkpoint=torch.load(path_save)\n",
    "        model_trained=GRU(input_size, hidden_size, nlayers, n_classes, dropout)\n",
    "        model_trained.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model_trained.to(device)\n",
    "        epoch = checkpoint['epoch']\n",
    "        # print(\"Best epoch is {}\".format(epoch))\n",
    "        pred_test_list = torch.zeros(y_test.shape).type(torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_trained.eval()\n",
    "            hidden_head = model_trained.init_hidden(1)\n",
    "            for i in range(len(x_test)):\n",
    "                pred_test,hiddens_test = model_trained(x_test[i][None,None,:],hidden_head)\n",
    "                hidden_head = hiddens_test\n",
    "                if i < len(x_test) - 1:\n",
    "                    x_test[i+1,-1] = pred_test[0,0,0]\n",
    "                pred_test_list[i,0] = pred_test[0,0,0]\n",
    "                if i % 40000 == 0:\n",
    "                    print(i)\n",
    "\n",
    "            loss_test = MSE(pred_test_list, y_test, m_test).cpu().numpy()\n",
    "            # print(\"Epoch {} : epoch_loss_train RMSE loss {:.4f}\".format(str(epoch), np.sqrt(loss_train)))\n",
    "            # print(\"Epoch {} : epoch_loss_test RMSE loss {:.4f}\".format(str(epoch), np.sqrt(loss_test)))\n",
    "            # print()\n",
    "            pred_test = pred_test_list.cpu().numpy()\n",
    "            hiddens_test = hiddens_test.cpu().numpy()\n",
    "        # Transform the output back to the original scale.\n",
    "        pred_test, y_test_ori = inverse_transform_sp(pred_test, y_test.cpu().numpy(), scaler_y, n_classes)\n",
    "        pred_test_itrs.append(pred_test)\n",
    "        \n",
    "    pred_test_itrs = np.squeeze(pred_test_itrs)\n",
    "    pred_test_itrs_data.append(pred_test_itrs)\n",
    "    y_sp = np.squeeze(y_test_sp.cpu().numpy())\n",
    "    m_sp = np.squeeze(m_test_sp.cpu().numpy())\n",
    "    y_ori =  y_sp.reshape(-1,n_classes)\n",
    "    y_ori = scaler_y.inverse_transform(y_ori).reshape(y_sp.shape)\n",
    "    idx_arr = test_idx_arr\n",
    "    \n",
    "    with open(exp_dir + \"pred_test_itrs.npy\", 'wb') as f:\n",
    "        np.save(f, pred_test_itrs)\n",
    "    with open(exp_dir + \"test_idx_arr.npy\", 'wb') as f:\n",
    "        np.save(f, test_idx_arr)\n",
    "    \n",
    "    rmse_test_itrs = []\n",
    "    nse_test_itrs=[]\n",
    "\n",
    "    for pred_test in pred_test_itrs:\n",
    "        rmse_test_itrs.append(np.sqrt(MSE(pred_test, np.squeeze(test_y))))\n",
    "        nse_test_itrs.append(get_NSE(np.squeeze(test_y), pred_test))\n",
    "        \n",
    "    print(\"Test RMSE Mean\")\n",
    "    print(np.round(rmse_test_itrs,3))\n",
    "    print(\"Test RMSE Mean : {:.3f}\".format(np.mean(rmse_test_itrs)))\n",
    "    print(\"Test RMSE STDV : {:.3f}\".format(np.std(rmse_test_itrs)))\n",
    "    \n",
    "    print(\"Test NSE\")\n",
    "    print(np.round(nse_test_itrs,3))\n",
    "    print(\"Test NSE Mean : {:.3f}\".format(np.mean(nse_test_itrs)))\n",
    "    print(\"Test NSE STDV : {:.3f}\".format(np.std(nse_test_itrs)))\n",
    "    \n",
    "    mean_rmse_data.append([train_years,np.mean(rmse_test_itrs)])\n",
    "    stdv_rmse_data.append([train_years,np.std(rmse_test_itrs)])\n",
    "    mean_nse_data.append([train_years,np.mean(nse_test_itrs)])\n",
    "    stdv_nse_data.append([train_years,np.std(nse_test_itrs)])\n",
    "    \n",
    "exp_dir = res_dir + '{}/rversion_{}/'.format(run_task, rversion)\n",
    "\n",
    "results_data = {'pred_test_itrs_data':np.squeeze(pred_test_itrs_data),\n",
    "               'mean_rmse_data':np.squeeze(mean_rmse_data), 'stdv_rmse_data':stdv_rmse_data,\n",
    "               'mean_nse_data':np.squeeze(mean_nse_data), 'stdv_nse_data':stdv_nse_data}\n",
    "with open(exp_dir+'results_data.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rmse_data = np.squeeze(mean_rmse_data)\n",
    "stdv_rmse_data = np.squeeze(stdv_rmse_data)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.errorbar(mean_rmse_data[:,0], mean_rmse_data[:,1], yerr=stdv_rmse_data[:,1], label='GRU')\n",
    "# plt.title('RMSE of models')\n",
    "plt.xlabel('training data size (years)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_a100",
   "language": "python",
   "name": "pytorch_a100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
